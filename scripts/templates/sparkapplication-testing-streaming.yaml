apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: streaming-spark-${UUID}
  namespace: spark-apps
  labels:
    app: spark-jobs
    applicationId: streaming-spark-${UUID}
    queue: "root.spark-apps"
spec:
  sparkConf:
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.InstanceProfileCredentialsProvider"
    "spark.kubernetes.local.dirs.tmpfs": "true"
    "spark.io.encryption.enabled": "true"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://${AWS_S3_BUCKET_SPARK_UI}/spark-ui"
    "spark.streaming.dynamicAllocation.enable": "true"
    "spark.dynamicAllocation.shuffleTracking.enabled": "true"
    "spark.dynamicAllocation.executorIdleTimeout": "60"
    "spark.dynamicAllocation.schedulerBacklogTimeout": "60"
  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    minExecutors: 2
    maxExecutors: 4
    shuffleTrackingTimeout: 120
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "${AWS_ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/spark-custom:3.2.0"
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "s3a://${AWS_S3_BUCKET_SPARK_UI}/data/src/jobs/example-002-streaming.py"
  sparkVersion: "3.2.0"
  volumes:
    - name: "spark-volume-testing-${UUID}"
      hostPath:
        path: "/tmp"
        type: Directory
  timeToLiveSeconds: 5
  batchScheduler: "yunikorn"
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 5
  driver:
    cores: 1
    coreRequest: "850m"
    memory: "2300m"
    memoryOverhead: "500m"
    labels:
      version: 3.2.0
    serviceAccount: spark
    volumeMounts:
      - name: "spark-volume-testing-${UUID}"
        mountPath: "/tmp"
    annotations:
      yunikorn.apache.org/schedulingPolicyParameters: "placeholderTimeoutSeconds=30"
      yunikorn.apache.org/task-group-name: "spark-driver-${UUID}"
      yunikorn.apache.org/task-groups: |-
        [
          {
            "name": "spark-driver-${UUID}",
            "minMember": 1,
            "minResource": {
              "cpu": "850m",
              "memory": "3000M"
            },
            "affinity": {
              "nodeAffinity": {
                "requiredDuringSchedulingIgnoredDuringExecution": {
                  "nodeSelectorTerms": [
                    {
                      "matchExpressions": [
                        {
                          "key": "workload",
                          "operator": "In",
                          "values": [
                            "${TYPE_WORKLOAD}-driver"
                          ]
                        }
                      ],
                      "topologyKey": "topology.kubernetes.io/zone"
                    }
                  ]
                }
              }
            }
          },
          {
            "name": "spark-executor-${UUID}",
            "minMember": 2,
            "minResource": {
              "cpu": "850m",
              "memory": "3000M"
            },
            "affinity": {
              "nodeAffinity": {
                "requiredDuringSchedulingIgnoredDuringExecution": {
                  "nodeSelectorTerms": [
                    {
                      "matchExpressions": [
                        {
                          "key": "workload",
                          "operator": "In",
                          "values": [
                            "${TYPE_WORKLOAD}-executor"
                          ]
                        }
                      ],
                      "topologyKey": "topology.kubernetes.io/zone"
                    }
                  ]
                }
              },
              "podAffinity": {
                "preferredDuringSchedulingIgnoredDuringExecution": [
                  {
                    "weight": 100,
                    "podAffinityTerm": {
                      "labelSelector": {
                        "matchExpressions": [
                          {
                            "key": "applicationId",
                            "operator": "In",
                            "values": [
                              "streaming-spark-${UUID}"
                            ]
                          }
                        ]
                      },
                      "topologyKey": "topology.kubernetes.io/zone"
                    }
                  }
                ]
              }
            }
          }
        ]
  executor:
    cores: 1
    instances: 2
    coreRequest: "850m"
    memory: "2300m"
    memoryOverhead: "500m"
    labels:
      version: 3.2.0
    volumeMounts:
      - name: "spark-volume-testing-${UUID}"
        mountPath: "/tmp"
    annotations:
      yunikorn.apache.org/task-group-name: "spark-executor-${UUID}"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: workload
              operator: In
              values:
              - "${TYPE_WORKLOAD}-executor"
      podAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: applicationId
                operator: In
                values:
                - streaming-spark-${UUID}
            topologyKey: topology.kubernetes.io/zone
